{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### chunk train videos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "datalist_path='/tsukimi/datasets/Chiba/baseline/datalist_3/train.csv'\n",
    "# read datalist\n",
    "datalist = pd.read_csv(datalist_path,header=None, delimiter=',')\n",
    "labels=list(datalist.values[:,1])\n",
    "videos=list(datalist.values[:,0])\n",
    "\n",
    "def process_video(video_path,label,segment_length = 17):\n",
    "    # read video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # print(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "    video_segments = []\n",
    "    \n",
    "    # clip video to 17 frames each\n",
    "    frame_count = 0\n",
    "    frames=[]\n",
    "    while True:\n",
    "        success = True\n",
    "        if not frames:\n",
    "            # read first frame\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "\n",
    "        for _ in range(segment_length-1):\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break \n",
    "            frames.append(frame)\n",
    "            \n",
    "        # Check if we have collected 17 frames\n",
    "        if len(frames) == segment_length:\n",
    "            start_frame = frame_count\n",
    "            end_frame = frame_count + segment_length - 1\n",
    "            segment_info = {\n",
    "                'video_path': video_path,\n",
    "                'label': label,\n",
    "                'start_frame': start_frame,\n",
    "                'end_frame': end_frame\n",
    "            }\n",
    "            video_segments.append(segment_info)\n",
    "            # reset frames, last frame will be used as first frame in next segment\n",
    "            frames = [frames[-1]]\n",
    "            frame_count=end_frame\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    df = pd.DataFrame(video_segments)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=process_video(videos[0],labels[0])\n",
    "for video, label in zip(videos[1:], labels[1:]):\n",
    "    df = process_video(video,label)\n",
    "    data = pd.concat([data, df], ignore_index=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to '/tsukimi/datasets/Chiba/baseline/datalist_3/train_16.csv'\n",
    "data.to_csv('/tsukimi/datasets/Chiba/baseline/datalist_3/train_16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count label distribution\n",
    "labels=data['label'].apply(lambda x:x.split('&'))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist={}\n",
    "for label in labels:\n",
    "    for l in label:\n",
    "        if l not in dist:\n",
    "            dist[l]=1\n",
    "        else:\n",
    "            dist[l]+=1\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if empty row exists\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/9_S2...</td>\n",
       "      <td>others&amp;restrainer_interaction</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/4_S3...</td>\n",
       "      <td>others&amp;others</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/4_S3...</td>\n",
       "      <td>others&amp;others</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/4_S3...</td>\n",
       "      <td>others&amp;others</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/4_S3...</td>\n",
       "      <td>others&amp;others</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117053</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/0_S1...</td>\n",
       "      <td>interaction_with_partner&amp;interaction_with_partner</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117054</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;restrainer_interaction</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117055</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;restrainer_interaction</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117056</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;restrainer_interaction</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117057</th>\n",
       "      <td>/tsukimi/datasets/Chiba/cut_videos_2label/1_S3...</td>\n",
       "      <td>restrainer_interaction&amp;restrainer_interaction</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117058 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               video_path  \\\n",
       "0       /tsukimi/datasets/Chiba/cut_videos_2label/9_S2...   \n",
       "1       /tsukimi/datasets/Chiba/cut_videos_2label/4_S3...   \n",
       "2       /tsukimi/datasets/Chiba/cut_videos_2label/4_S3...   \n",
       "3       /tsukimi/datasets/Chiba/cut_videos_2label/4_S3...   \n",
       "4       /tsukimi/datasets/Chiba/cut_videos_2label/4_S3...   \n",
       "...                                                   ...   \n",
       "117053  /tsukimi/datasets/Chiba/cut_videos_2label/0_S1...   \n",
       "117054  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "117055  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "117056  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "117057  /tsukimi/datasets/Chiba/cut_videos_2label/1_S3...   \n",
       "\n",
       "                                                    label  start_frame  \\\n",
       "0                           others&restrainer_interaction            0   \n",
       "1                                           others&others            0   \n",
       "2                                           others&others           16   \n",
       "3                                           others&others           32   \n",
       "4                                           others&others           48   \n",
       "...                                                   ...          ...   \n",
       "117053  interaction_with_partner&interaction_with_partner           64   \n",
       "117054      restrainer_interaction&restrainer_interaction            0   \n",
       "117055      restrainer_interaction&restrainer_interaction           16   \n",
       "117056      restrainer_interaction&restrainer_interaction           32   \n",
       "117057      restrainer_interaction&restrainer_interaction           48   \n",
       "\n",
       "        end_frame  \n",
       "0              16  \n",
       "1              16  \n",
       "2              32  \n",
       "3              48  \n",
       "4              64  \n",
       "...           ...  \n",
       "117053         80  \n",
       "117054         16  \n",
       "117055         32  \n",
       "117056         48  \n",
       "117057         64  \n",
       "\n",
       "[117058 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read datalist\n",
    "import pandas as pd\n",
    "datalist = pd.read_csv('/tsukimi/datasets/Chiba/baseline/datalist_3/train_16.csv')\n",
    "start_frame=list(map(float,datalist.values[:,2]))\n",
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'start_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mVideoDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainVideoDataset\n\u001b[0;32m----> 2\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mTrainVideoDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Events-ImageBind/datasets/VideoDataset.py:140\u001b[0m, in \u001b[0;36mTrainVideoDataset.__init__\u001b[0;34m(self, mode, frame_step, csv_path)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list\u001b[38;5;241m.\u001b[39mvalues[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list\u001b[38;5;241m.\u001b[39mvalues[:, \u001b[38;5;241m3\u001b[39m])) \n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_normalize \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m    143\u001b[0m         resize_pad,\n\u001b[1;32m    144\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize([\u001b[38;5;241m0.153\u001b[39m, \u001b[38;5;241m0.153\u001b[39m, \u001b[38;5;241m0.153\u001b[39m], [\u001b[38;5;241m0.165\u001b[39m, \u001b[38;5;241m0.165\u001b[39m, \u001b[38;5;241m0.165\u001b[39m])])\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'start_frame'"
     ]
    }
   ],
   "source": [
    "from datasets.VideoDataset import TrainVideoDataset\n",
    "data=TrainVideoDataset()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
