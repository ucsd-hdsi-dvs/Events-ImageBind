{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import torch\n",
    "from models import imagebind_model\n",
    "from models.imagebind_model import ModalityType\n",
    "\n",
    "text_list=[\"A dog.\", \"A car\", \"A bird\"]\n",
    "image_paths=[\".assets/dog_image.jpg\", \".assets/car_image.jpg\", \".assets/bird_image.jpg\"]\n",
    "audio_paths=[\".assets/dog_audio.wav\", \".assets/car_audio.wav\", \".assets/bird_audio.wav\"]\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiate model\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Load data\n",
    "inputs = {\n",
    "    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n",
    "    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n",
    "    ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device),\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(inputs)\n",
    "\n",
    "print(\n",
    "    \"Vision x Text: \",\n",
    "    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
    ")\n",
    "print(\n",
    "    \"Audio x Text: \",\n",
    "    torch.softmax(embeddings[ModalityType.AUDIO] @ embeddings[ModalityType.TEXT].T, dim=-1),\n",
    ")\n",
    "print(\n",
    "    \"Vision x Audio: \",\n",
    "    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.AUDIO].T, dim=-1),\n",
    ")\n",
    "\n",
    "# Expected output:\n",
    "#\n",
    "# Vision x Text:\n",
    "# tensor([[9.9761e-01, 2.3694e-03, 1.8612e-05],\n",
    "#         [3.3836e-05, 9.9994e-01, 2.4118e-05],\n",
    "#         [4.7997e-05, 1.3496e-02, 9.8646e-01]])\n",
    "#\n",
    "# Audio x Text:\n",
    "# tensor([[1., 0., 0.],\n",
    "#         [0., 1., 0.],\n",
    "#         [0., 0., 1.]])\n",
    "#\n",
    "# Vision x Audio:\n",
    "# tensor([[0.8070, 0.1088, 0.0842],\n",
    "#         [0.1036, 0.7884, 0.1079],\n",
    "#         [0.0018, 0.0022, 0.9960]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.AUDIO].T, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.multimodal_preprocessors import PatchEmbedGeneric,PadIm2Video\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "class PatchEmbedGeneric(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchEmbed from Hydra\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, proj_stem, norm_layer: Optional[nn.Module] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if len(proj_stem) > 1:\n",
    "            self.proj = nn.Sequential(*proj_stem)\n",
    "        else:\n",
    "            # Special case to be able to load pre-trained models that were\n",
    "            # trained with a standard stem\n",
    "            self.proj = proj_stem[0]\n",
    "        self.norm_layer = norm_layer\n",
    "\n",
    "    def get_patch_layout(self, img_size):\n",
    "        with torch.no_grad():\n",
    "            dummy_img = torch.zeros(\n",
    "                [\n",
    "                    1,\n",
    "                ]\n",
    "                + img_size\n",
    "            )\n",
    "            print(dummy_img.shape)\n",
    "            dummy_out = self.proj(dummy_img)\n",
    "        print(dummy_out.shape)\n",
    "        embed_dim = dummy_out.shape[1]\n",
    "        patches_layout = tuple(dummy_out.shape[2:])\n",
    "        num_patches = np.prod(patches_layout)\n",
    "        return patches_layout, num_patches, embed_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.proj(x)\n",
    "        print(x.shape)\n",
    "        # B C (T) H W -> B (T)HW C\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        print(x.shape)\n",
    "        if self.norm_layer is not None:\n",
    "            x = self.norm_layer(x)\n",
    "        return x\n",
    "    \n",
    "kernel_size=(2, 14, 14)\n",
    "vision_embed_dim=1024\n",
    "proj_stem=[\n",
    "                PadIm2Video(pad_type=\"repeat\", ntimes=2),\n",
    "                nn.Conv3d(\n",
    "                    in_channels=3,\n",
    "                    kernel_size=kernel_size,\n",
    "                    out_channels=vision_embed_dim,\n",
    "                    stride=kernel_size,\n",
    "                    bias=False,\n",
    "                )\n",
    "]\n",
    "PatchEmbedGeneric(proj_stem,None).get_patch_layout([3, 2,224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.helpers import VerboseNNModule\n",
    "from typing import Tuple, Optional, Callable\n",
    "from models.helpers import (EinOpsRearrange, LearnableLogitScaling, Normalize,\n",
    "                            SelectElement, SelectEOSAndProject)\n",
    "from models.multimodal_preprocessors import (AudioPreprocessor,\n",
    "                                             IMUPreprocessor, PadIm2Video,\n",
    "                                             PatchEmbedGeneric,\n",
    "                                             RGBDTPreprocessor,\n",
    "                                             SpatioTemporalPosEmbeddingHelper,\n",
    "                                             TextPreprocessor,\n",
    "                                             ThermalPreprocessor)\n",
    "from models.transformer import MultiheadAttention, SimpleTransformer\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from functools import partial\n",
    "from types import SimpleNamespace\n",
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RGBDTPreprocessor(VerboseNNModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rgbt_stem: PatchEmbedGeneric,\n",
    "        depth_stem: Optional[PatchEmbedGeneric],\n",
    "        img_size: Tuple = (3, 224, 224),\n",
    "        num_cls_tokens: int = 1,\n",
    "        pos_embed_fn: Optional[Callable] = None,\n",
    "        use_type_embed: bool = False,\n",
    "        init_param_style: str = \"openclip\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        stem = rgbt_stem if rgbt_stem is not None else depth_stem\n",
    "        (\n",
    "            self.patches_layout,\n",
    "            self.num_patches,\n",
    "            self.embed_dim,\n",
    "        ) = stem.get_patch_layout(img_size)\n",
    "        self.rgbt_stem = rgbt_stem\n",
    "        self.depth_stem = depth_stem\n",
    "        self.use_pos_embed = pos_embed_fn is not None\n",
    "        self.use_type_embed = use_type_embed\n",
    "        self.num_cls_tokens = num_cls_tokens\n",
    "\n",
    "        if self.use_pos_embed:\n",
    "            self.pos_embedding_helper = pos_embed_fn(\n",
    "                patches_layout=self.patches_layout,\n",
    "                num_cls_tokens=num_cls_tokens,\n",
    "                num_patches=self.num_patches,\n",
    "                embed_dim=self.embed_dim,\n",
    "            )\n",
    "        if self.num_cls_tokens > 0:\n",
    "            self.cls_token = nn.Parameter(\n",
    "                torch.zeros(1, self.num_cls_tokens, self.embed_dim)\n",
    "            )\n",
    "        if self.use_type_embed:\n",
    "            self.type_embed = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "\n",
    "        self.init_parameters(init_param_style)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_parameters(self, init_param_style):\n",
    "        if init_param_style == \"openclip\":\n",
    "            # OpenCLIP style initialization\n",
    "            scale = self.embed_dim**-0.5\n",
    "            if self.use_pos_embed:\n",
    "                nn.init.normal_(self.pos_embedding_helper.pos_embed)\n",
    "                self.pos_embedding_helper.pos_embed *= scale\n",
    "\n",
    "            if self.num_cls_tokens > 0:\n",
    "                nn.init.normal_(self.cls_token)\n",
    "                self.cls_token *= scale\n",
    "        elif init_param_style == \"vit\":\n",
    "            self.cls_token.data.fill_(0)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown init {init_param_style}\")\n",
    "\n",
    "        if self.use_type_embed:\n",
    "            nn.init.normal_(self.type_embed)\n",
    "\n",
    "    def tokenize_input_and_cls_pos(self, input, stem, mask):\n",
    "        # tokens is of shape B x L x D\n",
    "        tokens = stem(input)\n",
    "        assert tokens.ndim == 3\n",
    "        assert tokens.shape[2] == self.embed_dim\n",
    "        B = tokens.shape[0]\n",
    "        if self.num_cls_tokens > 0:\n",
    "            class_tokens = self.cls_token.expand(\n",
    "                B, -1, -1\n",
    "            )  # stole class_tokens impl from Phil Wang, thanks\n",
    "            tokens = torch.cat((class_tokens, tokens), dim=1)\n",
    "        if self.use_pos_embed:\n",
    "            pos_embed = self.pos_embedding_helper.get_pos_embedding(input, tokens)\n",
    "            tokens = tokens + pos_embed\n",
    "        if self.use_type_embed:\n",
    "            tokens = tokens + self.type_embed.expand(B, -1, -1)\n",
    "        return tokens\n",
    "\n",
    "    def forward(self, vision=None, depth=None, patch_mask=None):\n",
    "        if patch_mask is not None:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        if vision is not None:\n",
    "            vision_tokens = self.tokenize_input_and_cls_pos(\n",
    "                vision, self.rgbt_stem, patch_mask\n",
    "            )\n",
    "\n",
    "        if depth is not None:\n",
    "            depth_tokens = self.tokenize_input_and_cls_pos(\n",
    "                depth, self.depth_stem, patch_mask\n",
    "            )\n",
    "\n",
    "        # aggregate tokens\n",
    "        if vision is not None and depth is not None:\n",
    "            final_tokens = vision_tokens + depth_tokens\n",
    "        else:\n",
    "            final_tokens = vision_tokens if vision is not None else depth_tokens\n",
    "        return_dict = {\n",
    "            \"trunk\": {\n",
    "                \"tokens\": final_tokens,\n",
    "            },\n",
    "            \"head\": {},\n",
    "        }\n",
    "        return return_dict\n",
    "\n",
    "rgbt_stem = PatchEmbedGeneric(\n",
    "            proj_stem=[\n",
    "                PadIm2Video(pad_type=\"repeat\", ntimes=2),\n",
    "                nn.Conv3d(\n",
    "                    in_channels=3,\n",
    "                    kernel_size=kernel_size,\n",
    "                    out_channels=vision_embed_dim,\n",
    "                    stride=kernel_size,\n",
    "                    bias=False,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "rgbt_preprocessor = RGBDTPreprocessor(\n",
    "            img_size=[3, 2, 224, 224],\n",
    "            num_cls_tokens=1,\n",
    "            pos_embed_fn=partial(SpatioTemporalPosEmbeddingHelper, learnable=True),\n",
    "            rgbt_stem=rgbt_stem,\n",
    "            depth_stem=None,\n",
    "        )\n",
    "\n",
    "rgbt_preprocessor(dummy_img[0])['trunk']['tokens'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.imagebind_model import ImageBindModel\n",
    "imageBind=ImageBindModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([1, 3, 1, 224, 224])\n",
      "trunk_inputs shape torch.Size([1, 257, 1024])\n",
      "after trunk shape torch.Size([1, 257, 1024])\n",
      "after head shape torch.Size([1, 768])\n",
      "postprocessor shape torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dummy_img = torch.zeros(\n",
    "                [1,3,1,224,224]\n",
    "            )\n",
    "imageBind.layer_shapes(dummy_img,modality_type=\"vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "path='.checkpoints/imagebind_huge.pth'\n",
    "state_dict = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['modality_heads.thermal.2.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[keys for keys in state_dict.keys() if 'thermal' in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in state_dict.keys() if key.startswith(\"modality_preprocessors.thermal\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/imagebind/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.events.EventModel at 0x7f31cc63ca60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.events import EventModel\n",
    "e=EventModel()\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.0491, -0.0587, -0.0083,  ..., -0.0046,  0.0354,  0.0301]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.event_preprocessor.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0491, -0.0587, -0.0083,  ..., -0.0046,  0.0354,  0.0301]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.event_preprocessor.state_dict()['cls_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.load_weights(path='.checkpoints/imagebind_huge.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path='/tsukimi/datasets/Chiba/finetune_train/HL-HC-Official-2023_12_04_14_10_37-100.pkl'\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from datasets.EventDataset import events_to_image_torch as e2i\n",
    "with open(path, 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "def resize_pad(frame, size=224):\n",
    "    \"\"\"\n",
    "    resize a frame's longer side to 224, pad the shorter side to 224\n",
    "    \"\"\"\n",
    "\n",
    "    # get shape\n",
    "    c, h, w = frame.shape\n",
    "\n",
    "    # get longer side\n",
    "    longer_side = max(h, w)\n",
    "\n",
    "    # calculate ratio\n",
    "    ratio = size / longer_side\n",
    "\n",
    "    # resize with transform\n",
    "    resize_transform = transforms.Resize((int(h * ratio), int(w * ratio)))\n",
    "    frame = resize_transform(frame)\n",
    "\n",
    "    # get new shape\n",
    "    c, h, w = frame.shape\n",
    "\n",
    "    # calculate padding needed to reach size for both dimensions\n",
    "    pad_height = (size - h) if h < size else 0\n",
    "    pad_width = (size - w) if w < size else 0\n",
    "\n",
    "    # calculate padding for each side to center the image\n",
    "    pad_top = pad_height // 2\n",
    "    pad_bottom = pad_height - pad_top\n",
    "    pad_left = pad_width // 2\n",
    "    pad_right = pad_width - pad_left\n",
    "\n",
    "    # apply padding\n",
    "    padding_transform = transforms.Pad(padding=(pad_left, pad_top, pad_right, pad_bottom), fill=0, padding_mode='constant')\n",
    "    frame = padding_transform(frame)\n",
    "\n",
    "    return frame\n",
    "frame_normalize = transforms.Compose([\n",
    "                resize_pad,\n",
    "                transforms.Normalize([0.153, 0.153, 0.153], [0.165, 0.165, 0.165])])\n",
    "image_list = data['images'] \n",
    "image_list=[cv2.cvtColor(np.array(image),cv2.COLOR_BGR2RGB) for image in image_list]\n",
    "image_list = np.stack(image_list, axis=0)\n",
    "image_units = torch.from_numpy(image_list).float() / 255 \n",
    "image_units=image_units.permute(0,3, 1, 2) \n",
    "image_units = [frame_normalize(image_units[i]) for i in range(image_units.shape[0])]\n",
    "image_units = torch.stack(image_units)\n",
    "image_units=image_units.permute(1,0,2,3)\n",
    "print(image_units.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['events'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "events=data['events'][0]\n",
    "events['polarity'][events['polarity']==0]=-1\n",
    "events_positive=events[events['polarity']==1]\n",
    "events_negative=events[events['polarity']==-1]\n",
    "event_frame_positive=e2i(events_positive['x'],events_positive['y'],events_positive['polarity'])\n",
    "event_frame_negative=e2i(events_negative['x'],events_negative['y'],events_negative['polarity'])\n",
    "#find the indexes where eventframe not equals to 0\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(event_frame_negative, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(event_frame_positive, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa0e2fc9520>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concat image\n",
    "import numpy as np\n",
    "event_frame=np.stack([event_frame_positive,event_frame_negative,event_frame_positive+event_frame_negative])\n",
    "plt.imshow(np.transpose(event_frame,(1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 260, 346])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.EventDataset import events_to_image_torch as e2it\n",
    "import torch\n",
    "events=data['events'][0]\n",
    "events['polarity'][events['polarity']==0]=-1\n",
    "events_positive=events[events['polarity']==1]\n",
    "events_negative=events[events['polarity']==-1]\n",
    "\n",
    "# deep compare e2it(events_negative['x'],events_negative['y'],events_negative['polarity']) and event_frame_negative\n",
    "events_positive_frame=e2it(events_positive['x'],events_positive['y'],events_positive['polarity'])\n",
    "events_negative_frame=e2it(events_negative['x'],events_negative['y'],events_negative['polarity'])\n",
    "event_frame=torch.stack([events_positive_frame,events_negative_frame,events_positive_frame+events_negative_frame],dim=0)\n",
    "event_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_path={'train':['/tsukimi/datasets/Chiba/finetune_train/HL-HC-Official-2023_12_04_14_10_37-100.pkl']}\n",
    "import pickle\n",
    "#save dummy_path\n",
    "with open('dummy_path.pkl', 'wb') as f:\n",
    "    pickle.dump(dummy_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/imagebind/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/imagebind/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/imagebind/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets.EventDataset import EventDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "eventdataset=EventDataset(mode='train',data_dir='/tsukimi/datasets/Chiba/finetune_train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 2, 224, 224])\n",
      "('vision', 'vision', 'vision', 'vision', 'vision', 'vision', 'vision', 'vision')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loader=DataLoader(eventdataset,batch_size=8,shuffle=True)\n",
    "print(next(iter(loader))[0].shape)\n",
    "print(next(iter(loader))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/imagebind/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageBindModel(\n",
       "  (modality_preprocessors): ModuleDict(\n",
       "    (vision): RGBDTPreprocessor(\n",
       "      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
       "      \n",
       "      (rgbt_stem): PatchEmbedGeneric(\n",
       "        (proj): Sequential(\n",
       "          (0): PadIm2Video()\n",
       "          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
       "        \n",
       "      )\n",
       "    )\n",
       "    (text): TextPreprocessor(\n",
       "      (pos_embed): tensor((1, 77, 1024), requires_grad=True)\n",
       "      (mask): tensor((77, 77), requires_grad=False)\n",
       "      \n",
       "      (token_embedding): Embedding(49408, 1024)\n",
       "    )\n",
       "    (audio): AudioPreprocessor(\n",
       "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
       "      \n",
       "      (rgbt_stem): PatchEmbedGeneric(\n",
       "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "        (pos_embed): tensor((1, 229, 768), requires_grad=True)\n",
       "        \n",
       "      )\n",
       "    )\n",
       "    (depth): RGBDTPreprocessor(\n",
       "      (cls_token): tensor((1, 1, 384), requires_grad=True)\n",
       "      \n",
       "      (depth_stem): PatchEmbedGeneric(\n",
       "        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "        (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "        (pos_embed): tensor((1, 197, 384), requires_grad=True)\n",
       "        \n",
       "      )\n",
       "    )\n",
       "    (thermal): ThermalPreprocessor(\n",
       "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
       "      \n",
       "      (rgbt_stem): PatchEmbedGeneric(\n",
       "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "        (pos_embed): tensor((1, 197, 768), requires_grad=True)\n",
       "        \n",
       "      )\n",
       "    )\n",
       "    (imu): IMUPreprocessor(\n",
       "      (pos_embed): tensor((1, 251, 512), requires_grad=True)\n",
       "      (cls_token): tensor((1, 1, 512), requires_grad=True)\n",
       "      \n",
       "      (imu_stem): PatchEmbedGeneric(\n",
       "        (proj): Linear(in_features=48, out_features=512, bias=False)\n",
       "        (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (event): EventPreprocessor(\n",
       "      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
       "      \n",
       "      (rgbt_stem): PatchEmbedGeneric(\n",
       "        (proj): Sequential(\n",
       "          (0): PadIm2Video()\n",
       "          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
       "        \n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (modality_trunks): ModuleDict(\n",
       "    (vision): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (12): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (13): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (14): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (15): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (16): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (17): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (18): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (19): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (20): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (21): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (22): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (23): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (24): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (25): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (26): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (27): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (28): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (29): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (30): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (31): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (text): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (12): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (13): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (14): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (15): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (16): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (17): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (18): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (19): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (20): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (21): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (22): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (23): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (audio): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.009)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.018)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.036)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.045)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.055)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.064)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.073)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.082)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.091)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.100)\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (depth): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (thermal): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (imu): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): Identity()\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.140)\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.280)\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.420)\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.560)\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.700)\n",
       "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "    (event): SimpleTransformer(\n",
       "      (pre_transformer_layer): Sequential(\n",
       "        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): EinOpsRearrange()\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (6): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (7): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (8): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (9): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (10): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (11): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (12): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (13): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (14): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (15): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (16): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (17): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (18): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (19): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (20): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (21): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (22): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (23): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (24): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (25): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (26): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (27): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (28): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (29): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (30): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (31): BlockWithMasking(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (post_transformer_layer): EinOpsRearrange()\n",
       "    )\n",
       "  )\n",
       "  (modality_heads): ModuleDict(\n",
       "    (vision): Sequential(\n",
       "      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Linear(in_features=1280, out_features=1024, bias=False)\n",
       "    )\n",
       "    (text): SelectEOSAndProject(\n",
       "      (proj): Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (audio): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
       "    )\n",
       "    (depth): Sequential(\n",
       "      (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Linear(in_features=384, out_features=1024, bias=False)\n",
       "    )\n",
       "    (thermal): Sequential(\n",
       "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
       "    )\n",
       "    (imu): Sequential(\n",
       "      (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=1024, bias=False)\n",
       "    )\n",
       "    (event): Sequential(\n",
       "      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): SelectElement()\n",
       "      (2): Linear(in_features=1280, out_features=1024, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (modality_postprocessors): ModuleDict(\n",
       "    (vision): Normalize()\n",
       "    (text): Sequential(\n",
       "      (0): Normalize()\n",
       "      (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)\n",
       "    )\n",
       "    (audio): Sequential(\n",
       "      (0): Normalize()\n",
       "      (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)\n",
       "    )\n",
       "    (depth): Sequential(\n",
       "      (0): Normalize()\n",
       "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
       "    )\n",
       "    (thermal): Sequential(\n",
       "      (0): Normalize()\n",
       "      (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)\n",
       "    )\n",
       "    (imu): Sequential(\n",
       "      (0): Normalize()\n",
       "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
       "    )\n",
       "    (event): Normalize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import imagebind_model\n",
    "from models.events import EventModel\n",
    "model = imagebind_model.imagebind_huge(pretrained=True)\n",
    "eventmodel=EventModel()\n",
    "eventmodel.apply_event_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventPreprocessor(\n",
       "  (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
       "  \n",
       "  (rgbt_stem): PatchEmbedGeneric(\n",
       "    (proj): Sequential(\n",
       "      (0): PadIm2Video()\n",
       "      (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
       "    (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
       "    \n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.imagebind_model import ModalityType\n",
    "model.modality_preprocessors[ModalityType.EVENT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.imagebind_model import ModalityType\n",
    "img=eventdataset[0][0]\n",
    "event=eventdataset[0][2]\n",
    "with torch.no_grad():\n",
    "    inputs={ModalityType.VISION:img.unsqueeze(0),ModalityType.EVENT:event.unsqueeze(0)}\n",
    "    model.modality_preprocessors[ModalityType.EVENT](event.unsqueeze(0))\n",
    "    model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.multimodal_preprocessors import  PadIm2Video\n",
    "img=eventdataset[0][0]\n",
    "PadIm2Video(pad_type=\"repeat\", ntimes=2)(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 260, 346)\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "path='/tsukimi/datasets/MVSEC/mvsec_event_chunks_v2ce/indoor_flying1_data_left-1.pkl'\n",
    "# load data\n",
    "with open(path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(data['images'].shape)\n",
    "print(len(data['events']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
